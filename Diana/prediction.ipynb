{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec91175",
   "metadata": {},
   "source": [
    "### clean and tokenize your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f284fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T20:49:30.909255Z",
     "start_time": "2022-03-25T20:49:26.633739Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 17.9MB/s]                    \n",
      "2023-06-07 15:50:47 INFO: Downloading these customized packages for language: en (English)...\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | craft   |\n",
      "=======================\n",
      "\n",
      "2023-06-07 15:50:47 INFO: File exists: C:\\Users\\chern\\stanza_resources\\en\\tokenize\\craft.pt.\n",
      "2023-06-07 15:50:47 INFO: Finished downloading models and saved to C:\\Users\\chern\\stanza_resources.\n",
      "2023-06-07 15:50:47 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | craft   |\n",
      "=======================\n",
      "\n",
      "2023-06-07 15:50:47 INFO: Use device: cpu\n",
      "2023-06-07 15:50:47 INFO: Loading: tokenize\n",
      "2023-06-07 15:50:47 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en', package='craft', processors='tokenize')\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from copy import deepcopy\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "test_txt = '''\n",
    "Rh-based bimetallic catalysts are promising ligand-free heterogeneous catalysts for hydroformylation reactions. It is\n",
    "important to understand the mechanism of this bimetallic\n",
    "promotion for designing highly selective and active heterogenous\n",
    "catalysts. In this work, the RhCo bimetallic catalyst was\n",
    "investigated focusing on the promotion effect of Co for the gasphase hydroformylation of ethene. Adding Co to Rh increased both\n",
    "the catalytic productivity and selectivity to oxygenates. In situ\n",
    "diffuse reflectance infrared Fourier transform spectroscopy and\n",
    "CO-temperature programmed desorption were used to characterize\n",
    "CO adsorption. The results showed that the addition of Co to Rh\n",
    "changed the CO adsorption modes and strength for the Rh-based\n",
    "catalyst. Modulated CO adsorption strength was important to\n",
    "enhance selectivity. Density functional theory calculations were\n",
    "carried out to reveal the reaction mechanism. A reaction pathway was proposed to clarify the reason for enhanced selectivity on a\n",
    "RhCo bimetallic catalyst and show that the ratio between CO migration and desorption played a great role in this reaction. '''\n",
    "#load stanza tokenizer\n",
    "nlp = stanza.Pipeline('en', package='craft', processors='tokenize', use_gpu=False)\n",
    "\n",
    "test_sents = []\n",
    "idx = 0\n",
    "test_txt = cleanup_text(test_txt)\n",
    "for sent in nlp(test_txt).sentences:\n",
    "    sent_token = []\n",
    "    for token in sent.tokens:\n",
    "        # it is fine to label all token as O because it is not training\n",
    "        sent_token.append({\n",
    "            'text':token.text,\n",
    "            'label':'O',\n",
    "            \"id\":  idx,\n",
    "            \"start\": token.start_char,\n",
    "            \"end\": token.end_char,\n",
    "        })\n",
    "        idx += 1\n",
    "    test_sents.append((sent.text, sent_token))\n",
    "test_sents = stanza_fix(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba77595",
   "metadata": {},
   "source": [
    "### predict using model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a296fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T20:49:37.467924Z",
     "start_time": "2022-03-25T20:49:30.911730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.3.4 to v1.9.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file C:\\Users\\chern\\Documents\\GitHub\\CatalysisIE\\checkpoint\\CV_0.ckpt`\n",
      "Global seed set to 12345\n",
      "Some weights of the model checkpoint at pretrained/scibert_domain_adaption were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrained/scibert_domain_adaption and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Global seed set to 12345\n",
      "Global seed set to 12345\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rh-based bimetallic catalysts are promising ligand-free heterogeneous catalysts for hydroformylation reactions.\n",
      "Rh-based bimetallic catalysts Catalyst\n",
      "hydroformylation Reaction\n",
      "\n",
      "\n",
      "\n",
      "It is important to understand the mechanism of this bimetallic promotion for designing highly selective and active heterogenous catalysts.\n",
      "\n",
      "\n",
      "\n",
      "In this work, the RhCo bimetallic catalyst was investigated focusing on the promotion effect of Co for the gasphase hydroformylation of ethene.\n",
      "RhCo bimetallic catalyst Catalyst\n",
      "Co Catalyst\n",
      "gasphase hydroformylation Reaction\n",
      "ethene Reactant\n",
      "\n",
      "\n",
      "\n",
      "Adding Co to Rh increased both the catalytic productivity and selectivity to oxygenates.\n",
      "Co Catalyst\n",
      "Rh Catalyst\n",
      "oxygenates Product\n",
      "\n",
      "\n",
      "\n",
      "In situ diffuse reflectance infrared Fourier transform spectroscopy and CO-temperature programmed desorption were used to characterize CO adsorption.\n",
      "In situ diffuse reflectance infrared Fourier transform spectroscopy Characterization\n",
      "CO-temperature programmed desorption Characterization\n",
      "\n",
      "\n",
      "\n",
      "The results showed that the addition of Co to Rh changed the CO adsorption modes and strength for the Rh-based catalyst.\n",
      "Co Catalyst\n",
      "Rh Catalyst\n",
      "Rh-based catalyst Catalyst\n",
      "\n",
      "\n",
      "\n",
      "Modulated CO adsorption strength was important to enhance selectivity.\n",
      "\n",
      "\n",
      "\n",
      "Density functional theory calculations were carried out to reveal the reaction mechanism.\n",
      "\n",
      "\n",
      "\n",
      "A reaction pathway was proposed to clarify the reason for enhanced selectivity on a RhCo bimetallic catalyst and show that the ratio between CO migration and desorption played a great role in this reaction.\n",
      "RhCo bimetallic catalyst Catalyst\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from copy import deepcopy\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "#use the checkpoint trained on first fold\n",
    "ckpt_name = 'checkpoint/CV_0.ckpt'\n",
    "bert_name = 'pretrained/scibert_domain_adaption'\n",
    "model = BERTSpan.load_from_checkpoint(ckpt_name, model_name=bert_name, train_dataset=[], val_dataset=[], test_dataset=[])\n",
    "\n",
    "def pred_model_dataset(model, sent):\n",
    "    output_tensor_buf = []\n",
    "    pred_dataset, pred_dataloader = model.gen_pred_dataloader(sent)\n",
    "    \n",
    "    model.setup('test')\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        offset = 0\n",
    "        for batch in tqdm(pred_dataloader):\n",
    "            batch = model.batch_cuda(batch)\n",
    "            model.pred_dataset_step(offset, batch, pred_dataset)\n",
    "            offset += len(batch[0])\n",
    "    return pred_dataset.output_pred()\n",
    "\n",
    "\n",
    "output_sents = pred_model_dataset(model, test_sents)\n",
    "for sent in output_sents:\n",
    "    sent_tag = [t['pred'] for t in sent]\n",
    "    print(assemble_token_text(sent))\n",
    "    for i,j,l in get_bio_spans(sent_tag):\n",
    "        print(assemble_token_text(sent[i:j+1]), l)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d26cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Quantity(0.6, \"Unit(name=\"south african rand hour\", entity=Entity(\"unknown\"), uri=None)\"),\n",
       " Quantity(44, \"Unit(name=\"mole\", entity=Entity(\"amount of substance\"), uri=Mole_(unit))\"),\n",
       " Quantity(2511, \"Unit(name=\"per hour ampere-turn\", entity=Entity(\"unknown\"), uri=None)\"),\n",
       " Quantity(5, \"Unit(name=\"hour\", entity=Entity(\"time\"), uri=Hour)\")]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantulum3 import parser\n",
    "quants = parser.parse('For 0.6Rh/SiO2, the catalyst productivity was 44 mol/(molRh·h) and the TOF was 2511 h−1 at the time on stream (TOS) of 5 h')\n",
    "quants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "494fde07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rh', 'Co', 'O']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usefull code lines\n",
    "string= 'RhCoO'\n",
    "str_pattern = r'([A-Z](?:[a-z])?)'\n",
    "pattern= re.compile(str_pattern)\n",
    "result = pattern.findall(string)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebf8db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def chemical_prep(chem_list):\n",
    "    long_chem = {}\n",
    "    comp_dict = {}\n",
    "    for entity in chem_list:\n",
    "        entity_split = entity.split()\n",
    "        if len(string_list) >= 2 or re.match(r'[A-Za-z]([a-z]){3,}', string) is not None:\n",
    "            comp = re.findall(r'([A-Z](?:[a-z])?)',entity)\n",
    "            comp_dict[entity] = comp\n",
    "        else:\n",
    "            chem_dict[entity] = entity_split  \n",
    "    return chem_dict, comp_dict\n",
    "\n",
    "\n",
    "def ont_comp_lookup (comp_dict,onto):\n",
    "    for k,v in comp_dict.items():\n",
    "        for comp in v:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7e5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dea353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from copy import deepcopy\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "#use the checkpoint trained on first fold\n",
    "ckpt_name = 'checkpoint/CV_0.ckpt'\n",
    "bert_name = 'pretrained/scibert_domain_adaption'\n",
    "model = BERTSpan.load_from_checkpoint(ckpt_name, model_name=bert_name, train_dataset=[], val_dataset=[], test_dataset=[])\n",
    "\n",
    "def pred_model_dataset(model, sent):\n",
    "    output_tensor_buf = []\n",
    "    pred_dataset, pred_dataloader = model.gen_pred_dataloader(sent)\n",
    "    \n",
    "    model.setup('test')\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        offset = 0\n",
    "        for batch in tqdm(pred_dataloader):\n",
    "            batch = model.batch_cuda(batch)\n",
    "            model.pred_dataset_step(offset, batch, pred_dataset)\n",
    "            offset += len(batch[0])\n",
    "    return pred_dataset.output_pred()\n",
    "\n",
    "\n",
    "output_sents = pred_model_dataset(model, test_sents)\n",
    "for sent in output_sents:\n",
    "    sent_tag = [t['pred'] for t in sent]\n",
    "    print(assemble_token_text(sent))\n",
    "    for i,j,l in get_bio_spans(sent_tag):\n",
    "        print(assemble_token_text(sent[i:j+1]), l)\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
